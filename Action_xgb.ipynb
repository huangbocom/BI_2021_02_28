{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  merchant_id label origin  age_range  gender\n",
      "0       365952         1203   0.0  train          0       1\n",
      "1        42624          946   0.0  train          2       0\n",
      "2       240000         2278   0.0  train          3       0\n",
      "3       177792          951   0.0  train          0       1\n",
      "4       322944         1892   0.0  train          7       0\n",
      "...        ...          ...   ...    ...        ...     ...\n",
      "23888    47231         1748   nan   test          0       0\n",
      "23889    59519          798   nan   test          3       0\n",
      "23890   263039          639   nan   test          2       1\n",
      "23891   263039         3954   nan   test          2       1\n",
      "23892   423551         2954   nan   test          4       0\n",
      "\n",
      "[23893 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-b2c18475b546>:84: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = groups['user_id', 'item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'user_id':'m2', 'item_id':'m3', 'cat_id':'m4', 'brand_id':'m5'})\n",
      "<ipython-input-5-b2c18475b546>:98: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  temp = groups['item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'um2', 'cat_id':'um3', 'brand_id':'um4'}) #统计item_id, cat_id, brand_id唯一个数\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  merchant_id label origin    u1   u2  u3  u4  u5        u6  \\\n",
      "0       365952         1203   0.0  train    46   29  12  16  16  4.933333   \n",
      "1        42624          946   0.0  train   365  198  46  46  45  5.866667   \n",
      "2       240000         2278   0.0  train    47   31  14  15  17  5.833333   \n",
      "3       177792          951   0.0  train   234  105  23  35  36  5.833333   \n",
      "4       322944         1892   0.0  train   186  106  34  40  39  5.866667   \n",
      "...        ...          ...   ...    ...   ...  ...  ..  ..  ..       ...   \n",
      "23888    47231         1748   nan   test   128   97  28  39  40  5.816667   \n",
      "23889    59519          798   nan   test  1286  540  55  93  96  6.000000   \n",
      "23890   263039          639   nan   test     9    8   7   7   7  5.783333   \n",
      "23891   263039         3954   nan   test     9    8   7   7   7  5.783333   \n",
      "23892   423551         2954   nan   test   197   85  36  39  40  5.916667   \n",
      "\n",
      "       ...  age_2  age_3  age_4  age_5  age_6  age_7  age_8  g_0  g_1  g_2  \n",
      "0      ...      0      0      0      0      0      0      0    0    1    0  \n",
      "1      ...      1      0      0      0      0      0      0    1    0    0  \n",
      "2      ...      0      1      0      0      0      0      0    1    0    0  \n",
      "3      ...      0      0      0      0      0      0      0    0    1    0  \n",
      "4      ...      0      0      0      0      0      1      0    1    0    0  \n",
      "...    ...    ...    ...    ...    ...    ...    ...    ...  ...  ...  ...  \n",
      "23888  ...      0      0      0      0      0      0      0    1    0    0  \n",
      "23889  ...      0      1      0      0      0      0      0    1    0    0  \n",
      "23890  ...      1      0      0      0      0      0      0    0    1    0  \n",
      "23891  ...      1      0      0      0      0      0      0    0    1    0  \n",
      "23892  ...      0      0      1      0      0      0      0    1    0    0  \n",
      "\n",
      "[23893 rows x 47 columns]\n",
      "[0]\tvalidation_0-auc:0.61162\tvalidation_1-auc:0.58807\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 50 rounds.\n",
      "[1]\tvalidation_0-auc:0.62081\tvalidation_1-auc:0.59083\n",
      "[2]\tvalidation_0-auc:0.62873\tvalidation_1-auc:0.58296\n",
      "[3]\tvalidation_0-auc:0.63275\tvalidation_1-auc:0.58096\n",
      "[4]\tvalidation_0-auc:0.63113\tvalidation_1-auc:0.59002\n",
      "[5]\tvalidation_0-auc:0.63359\tvalidation_1-auc:0.61181\n",
      "[6]\tvalidation_0-auc:0.63414\tvalidation_1-auc:0.60336\n",
      "[7]\tvalidation_0-auc:0.63294\tvalidation_1-auc:0.59447\n",
      "[8]\tvalidation_0-auc:0.62913\tvalidation_1-auc:0.58934\n",
      "[9]\tvalidation_0-auc:0.62621\tvalidation_1-auc:0.59541\n",
      "[10]\tvalidation_0-auc:0.63005\tvalidation_1-auc:0.59803\n",
      "[11]\tvalidation_0-auc:0.63103\tvalidation_1-auc:0.59330\n",
      "[12]\tvalidation_0-auc:0.63051\tvalidation_1-auc:0.59568\n",
      "[13]\tvalidation_0-auc:0.62914\tvalidation_1-auc:0.59673\n",
      "[14]\tvalidation_0-auc:0.62739\tvalidation_1-auc:0.59431\n",
      "[15]\tvalidation_0-auc:0.62619\tvalidation_1-auc:0.59183\n",
      "[16]\tvalidation_0-auc:0.62691\tvalidation_1-auc:0.59572\n",
      "[17]\tvalidation_0-auc:0.62684\tvalidation_1-auc:0.59770\n",
      "[18]\tvalidation_0-auc:0.62597\tvalidation_1-auc:0.59581\n",
      "[19]\tvalidation_0-auc:0.62720\tvalidation_1-auc:0.59696\n",
      "[20]\tvalidation_0-auc:0.62811\tvalidation_1-auc:0.59779\n",
      "[21]\tvalidation_0-auc:0.62729\tvalidation_1-auc:0.59633\n",
      "[22]\tvalidation_0-auc:0.62817\tvalidation_1-auc:0.59583\n",
      "[23]\tvalidation_0-auc:0.62806\tvalidation_1-auc:0.59773\n",
      "[24]\tvalidation_0-auc:0.62721\tvalidation_1-auc:0.59534\n",
      "[25]\tvalidation_0-auc:0.62850\tvalidation_1-auc:0.59643\n",
      "[26]\tvalidation_0-auc:0.62823\tvalidation_1-auc:0.59911\n",
      "[27]\tvalidation_0-auc:0.62904\tvalidation_1-auc:0.60032\n",
      "[28]\tvalidation_0-auc:0.62914\tvalidation_1-auc:0.60094\n",
      "[29]\tvalidation_0-auc:0.62848\tvalidation_1-auc:0.60200\n",
      "[30]\tvalidation_0-auc:0.62968\tvalidation_1-auc:0.60314\n",
      "[31]\tvalidation_0-auc:0.62931\tvalidation_1-auc:0.60184\n",
      "[32]\tvalidation_0-auc:0.63058\tvalidation_1-auc:0.60085\n",
      "[33]\tvalidation_0-auc:0.63130\tvalidation_1-auc:0.60130\n",
      "[34]\tvalidation_0-auc:0.63113\tvalidation_1-auc:0.60274\n",
      "[35]\tvalidation_0-auc:0.63186\tvalidation_1-auc:0.60413\n",
      "[36]\tvalidation_0-auc:0.63218\tvalidation_1-auc:0.60303\n",
      "[37]\tvalidation_0-auc:0.63153\tvalidation_1-auc:0.60111\n",
      "[38]\tvalidation_0-auc:0.63110\tvalidation_1-auc:0.60064\n",
      "[39]\tvalidation_0-auc:0.63052\tvalidation_1-auc:0.60138\n",
      "[40]\tvalidation_0-auc:0.63136\tvalidation_1-auc:0.60249\n",
      "[41]\tvalidation_0-auc:0.63151\tvalidation_1-auc:0.60292\n",
      "[42]\tvalidation_0-auc:0.63183\tvalidation_1-auc:0.60208\n",
      "[43]\tvalidation_0-auc:0.63115\tvalidation_1-auc:0.60293\n",
      "[44]\tvalidation_0-auc:0.63100\tvalidation_1-auc:0.60201\n",
      "[45]\tvalidation_0-auc:0.63181\tvalidation_1-auc:0.60155\n",
      "[46]\tvalidation_0-auc:0.63148\tvalidation_1-auc:0.60071\n",
      "[47]\tvalidation_0-auc:0.63152\tvalidation_1-auc:0.60139\n",
      "[48]\tvalidation_0-auc:0.63209\tvalidation_1-auc:0.60148\n",
      "[49]\tvalidation_0-auc:0.63255\tvalidation_1-auc:0.60257\n",
      "[50]\tvalidation_0-auc:0.63212\tvalidation_1-auc:0.60450\n",
      "[51]\tvalidation_0-auc:0.63216\tvalidation_1-auc:0.60398\n",
      "[52]\tvalidation_0-auc:0.63255\tvalidation_1-auc:0.60505\n",
      "[53]\tvalidation_0-auc:0.63224\tvalidation_1-auc:0.60662\n",
      "[54]\tvalidation_0-auc:0.63203\tvalidation_1-auc:0.60562\n",
      "[55]\tvalidation_0-auc:0.63232\tvalidation_1-auc:0.60650\n",
      "Stopping. Best iteration:\n",
      "[5]\tvalidation_0-auc:0.63359\tvalidation_1-auc:0.61181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "# 用户行为，使用format1进行加载\n",
    "# 加载全量样本\n",
    "\"\"\"\n",
    "user_log = pd.read_csv('./user_log_format1.csv', dtype={'time_stamp':'str'})\n",
    "user_info = pd.read_csv('./user_info_format1.csv')\n",
    "train_data1 = pd.read_csv('./train_format1.csv')\n",
    "submission = pd.read_csv('./test_format1.csv')\n",
    "\"\"\"\n",
    "# 加载小样本\n",
    "user_log = pd.read_csv('./sample_user_log.csv', dtype={'time_stamp':'str'})\n",
    "user_info = pd.read_csv('./sample_user_info.csv')\n",
    "train_data1 = pd.read_csv('./train.csv')\n",
    "submission = pd.read_csv('./test.csv')\n",
    "\n",
    "train_data = pd.read_csv('./train_format2.csv')\n",
    "\n",
    "train_data1['origin'] = 'train'\n",
    "submission['origin'] = 'test'\n",
    "matrix = pd.concat([train_data1, submission], ignore_index=True, sort=False)\n",
    "#print(matrix)\n",
    "\n",
    "matrix.drop(['prob'], axis=1, inplace=True)\n",
    "# 连接user_info表，通过user_id关联\n",
    "matrix = matrix.merge(user_info, on='user_id', how='left')\n",
    "# 使用merchant_id（原列名seller_id）\n",
    "user_log.rename(columns={'seller_id':'merchant_id'}, inplace=True)\n",
    "# 格式化\n",
    "user_log['user_id'] = user_log['user_id'].astype('int32')\n",
    "user_log['merchant_id'] = user_log['merchant_id'].astype('int32')\n",
    "user_log['item_id'] = user_log['item_id'].astype('int32')\n",
    "user_log['cat_id'] = user_log['cat_id'].astype('int32')\n",
    "user_log['brand_id'].fillna(0, inplace=True)\n",
    "user_log['brand_id'] = user_log['brand_id'].astype('int32')\n",
    "user_log['time_stamp'] = pd.to_datetime(user_log['time_stamp'], format='%H%M')\n",
    "# 1 for <18; 2 for [18,24]; 3 for [25,29]; 4 for [30,34]; 5 for [35,39]; 6 for [40,49]; 7 and 8 for >= 50; 0 and NULL for unknown\n",
    "matrix['age_range'].fillna(0, inplace=True)\n",
    "# 0:female, 1:male, 2:unknown\n",
    "matrix['gender'].fillna(2, inplace=True)\n",
    "matrix['age_range'] = matrix['age_range'].astype('int8')\n",
    "matrix['gender'] = matrix['gender'].astype('int8')\n",
    "matrix['label'] = matrix['label'].astype('str')\n",
    "matrix['user_id'] = matrix['user_id'].astype('int32')\n",
    "matrix['merchant_id'] = matrix['merchant_id'].astype('int32')\n",
    "del user_info, train_data1\n",
    "gc.collect()\n",
    "print(matrix)\n",
    "\n",
    "# User特征处理\n",
    "groups = user_log.groupby(['user_id'])\n",
    "# 用户交互行为数量 u1\n",
    "temp = groups.size().reset_index().rename(columns={0:'u1'})\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "# 使用agg 基于列的聚合操作，统计唯一值的个数 item_id, cat_id, merchant_id, brand_id\n",
    "#temp = groups['item_id', 'cat_id', 'merchant_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'u2', 'cat_id':'u3', 'merchant_id':'u4', 'brand_id':'u5'})\n",
    "# 对于每个user_id 不重复的item_id的数量 => u2\n",
    "temp = groups['item_id'].agg([('u2', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "# 对于每个user_id 不重复的cat_id的数量 => u3\n",
    "temp = groups['cat_id'].agg([('u3', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "temp = groups['merchant_id'].agg([('u4', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "temp = groups['brand_id'].agg([('u5', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "\n",
    "# 时间间隔特征 u6 按照小时\n",
    "# 对于每个user_id 计算time_stamp的最小时间 => F_time, 最大时间max => L_time\n",
    "temp = groups['time_stamp'].agg([('F_time', 'min'), ('L_time', 'max')]).reset_index()\n",
    "temp['u6'] = (temp['L_time'] - temp['F_time']).dt.seconds/3600\n",
    "matrix = matrix.merge(temp[['user_id', 'u6']], on='user_id', how='left')\n",
    "# 统计操作类型为0，1，2，3的个数\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'u7', 1:'u8', 2:'u9', 3:'u10'})\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "#print(matrix)\n",
    "\n",
    "# 商家特征处理\n",
    "groups = user_log.groupby(['merchant_id'])\n",
    "# 商家被交互行为数量 m1\n",
    "temp = groups.size().reset_index().rename(columns={0:'m1'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "# 统计商家被交互的user_id, item_id, cat_id, brand_id 唯一值\n",
    "temp = groups['user_id', 'item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'user_id':'m2', 'item_id':'m3', 'cat_id':'m4', 'brand_id':'m5'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "# 统计商家被交互的action_type 唯一值\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'m6', 1:'m7', 2:'m8', 3:'m9'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "# 按照merchant_id 统计随机负采样的个数\n",
    "temp = train_data[train_data['label']==-1].groupby(['merchant_id']).size().reset_index().rename(columns={0:'m10'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "#print(matrix)\n",
    "\n",
    "# 按照user_id, merchant_id分组\n",
    "groups = user_log.groupby(['user_id', 'merchant_id'])\n",
    "temp = groups.size().reset_index().rename(columns={0:'um1'}) #统计行为个数\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "temp = groups['item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'um2', 'cat_id':'um3', 'brand_id':'um4'}) #统计item_id, cat_id, brand_id唯一个数\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'um5', 1:'um6', 2:'um7', 3:'um8'})#统计不同action_type唯一个数\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "temp = groups['time_stamp'].agg([('first', 'min'), ('last', 'max')]).reset_index()\n",
    "temp['um9'] = (temp['last'] - temp['first']).dt.seconds/3600\n",
    "temp.drop(['first', 'last'], axis=1, inplace=True)\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left') #统计时间间隔\n",
    "#print(matrix)\n",
    "\n",
    "#用户购买点击比\n",
    "matrix['r1'] = matrix['u9']/matrix['u7'] \n",
    "#商家购买点击比\n",
    "matrix['r2'] = matrix['m8']/matrix['m6'] \n",
    "#不同用户不同商家购买点击比\n",
    "matrix['r3'] = matrix['um7']/matrix['um5']\n",
    "matrix.fillna(0, inplace=True)\n",
    "# # 修改age_range字段名称为 age_0, age_1, age_2... age_8\n",
    "temp = pd.get_dummies(matrix['age_range'], prefix='age')\n",
    "matrix = pd.concat([matrix, temp], axis=1)\n",
    "temp = pd.get_dummies(matrix['gender'], prefix='g')\n",
    "matrix = pd.concat([matrix, temp], axis=1)\n",
    "matrix.drop(['age_range', 'gender'], axis=1, inplace=True)\n",
    "print(matrix)\n",
    "\n",
    "# 分割训练数据和测试数据\n",
    "train_data = matrix[matrix['origin'] == 'train'].drop(['origin'], axis=1)\n",
    "test_data = matrix[matrix['origin'] == 'test'].drop(['label', 'origin'], axis=1)\n",
    "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']\n",
    "del temp, matrix\n",
    "gc.collect()\n",
    "\n",
    "# 使用机器学习工具\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "# 将训练集进行切分，20%用于验证\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_X, train_y, test_size=.2)\n",
    "\n",
    "# 使用XGBoost\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=8,\n",
    "    n_estimators=3000,\n",
    "    min_child_weight=300, \n",
    "    colsample_bytree=0.8, \n",
    "    subsample=0.8, \n",
    "    eta=0.3,    \n",
    "    seed=42    \n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_metric='auc', eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    verbose=True,\n",
    "    #早停法，如果auc在10epoch没有进步就stop\n",
    "    early_stopping_rounds=50 \n",
    ")\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "prob = model.predict_proba(test_data)\n",
    "submission['prob'] = pd.Series(prob[:,1])\n",
    "submission.drop(['origin'], axis=1, inplace=True)\n",
    "submission.to_csv('prediction.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
